{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for package\n",
    "import nltk\n",
    "import docx\n",
    "import os\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to read .docx files\n",
    "\n",
    "def getText(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return '\\n'.join(fullText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all candidate data\n",
    "os.chdir('Candidate Data/')\n",
    "\n",
    "    # Load Vicuna data\n",
    "os.chdir('Vicuna/')\n",
    "vicunaPaths = os.listdir()\n",
    "vicunaPaths.sort()\n",
    "\n",
    "vicunaCandidates = []\n",
    "for file in vicunaPaths:\n",
    "    vicunaCandidates.append(getText(file))\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "    # Load LLaMA data\n",
    "os.chdir('LLaMA/')\n",
    "llamaPaths = os.listdir()\n",
    "llamaPaths.sort()\n",
    "\n",
    "llamaCandidates = []\n",
    "for file in llamaPaths:\n",
    "    llamaCandidates.append(getText(file))\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Vicuna: 0.1334261082503565\n",
      "Score LLaMA: 0.1334261082503565\n",
      "Score Vicuna: 0.10790250811745826\n",
      "Score LLaMA: 0.10790250811745826\n",
      "Score Vicuna: 0.15128410804203973\n",
      "Score LLaMA: 0.15128410804203973\n",
      "Score Vicuna: 0.14217224747135587\n",
      "Score LLaMA: 0.14217224747135587\n",
      "Score Vicuna: 0.10838976994036544\n",
      "Score LLaMA: 0.10838976994036544\n",
      "Score Vicuna: 0.1519764668868514\n",
      "Score LLaMA: 0.1519764668868514\n",
      "Score Vicuna: 0.15016717282434494\n",
      "Score LLaMA: 0.15016717282434494\n",
      "Score Vicuna: 0.1307070766907517\n",
      "Score LLaMA: 0.1307070766907517\n",
      "Score Vicuna: 0.1268609175774478\n",
      "Score LLaMA: 0.1268609175774478\n",
      "Score Vicuna: 0.14323715041300392\n",
      "Score LLaMA: 0.14323715041300392\n",
      "Score Vicuna: 0.11413892227137264\n",
      "Score LLaMA: 0.11413892227137264\n",
      "Score Vicuna: 0.09705597256190784\n",
      "Score LLaMA: 0.09705597256190784\n",
      "Score Vicuna: 0.09614593267069207\n",
      "Score LLaMA: 0.09614593267069207\n",
      "Score Vicuna: 0.10695861063636514\n",
      "Score LLaMA: 0.10695861063636514\n",
      "Score Vicuna: 0.13896107773051675\n",
      "Score LLaMA: 0.13896107773051675\n",
      "Score Vicuna: 0.11584878694786682\n",
      "Score LLaMA: 0.11584878694786682\n",
      "Score Vicuna: 0.16418304703291686\n",
      "Score LLaMA: 0.16418304703291686\n",
      "Score Vicuna: 0.11487838532265379\n",
      "Score LLaMA: 0.11487838532265379\n"
     ]
    }
   ],
   "source": [
    "# Load all reference data\n",
    "\n",
    "os.chdir('Reference Data/')\n",
    "referencePaths = os.listdir()\n",
    "referencePaths.sort()\n",
    "\n",
    "reference = []\n",
    "for file, index in zip(referencePaths, range(len(referencePaths))):\n",
    "    reference = getText(file).split()\n",
    "\n",
    "    print('Score Vicuna: {}'.format(sentence_bleu(reference, vicunaCandidates[index])))\n",
    "    print('Score LLaMA: {}'.format(sentence_bleu(reference, vicunaCandidates[index])))\n",
    "    # print(reference)\n",
    "    # print(vicunaCandidates[index])\n",
    "\n",
    "\n",
    "    # Go back\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/siddh/Projects/Language-Model-Evaluation-Scripts/Reference Data\n",
      "/home/siddh/Projects/Language-Model-Evaluation-Scripts\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "print(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LMEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
